{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mqVupoblYAaj",
    "outputId": "2cc053bd-039a-4073-f931-d1287fac8af4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "MvIOhOOICMTG"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as tfk\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, BatchNormalization, MaxPool2D, GlobalAveragePooling2D, Dense, Dropout, Activation\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "j_Wd6MqFCMTO"
   },
   "outputs": [],
   "source": [
    "data_dir = \"../input/vietai-c6-assignment3-extracted-dataset/train.csv\"\n",
    "sub_dir = \"../input/vietai-c6-assignment3-extracted-dataset/sample_submission.csv\"\n",
    "train_df = pd.read_csv(data_dir)\n",
    "sub_df = pd.read_csv(sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "69COWsDICMTS",
    "outputId": "8ede7305-5c14-4e3b-d948-6624fa6515ab"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image  label\n",
       "0     0.jpg      0\n",
       "1     1.jpg      3\n",
       "2    10.jpg      2\n",
       "3   100.jpg      0\n",
       "4  1000.jpg      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "n3EHv2GNCMTZ",
    "outputId": "02048819-3781-4508-fc7e-395ea852b6db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10010.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10011.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10028.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10034.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10056.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image  label\n",
       "0  10010.jpg      0\n",
       "1  10011.jpg      0\n",
       "2  10028.jpg      0\n",
       "3  10034.jpg      0\n",
       "4  10056.jpg      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7corOiJCCMTe"
   },
   "outputs": [],
   "source": [
    "classes = [\"book\", \"can\", \"cardboard\", \"glass_bottle\", \"pen\", \"plastic_bottle\"]\n",
    "train_y = train_y = train_df.label\n",
    "num_classes = len(np.unique(train_y))\n",
    "y_ohe = tf.keras.utils.to_categorical(train_y, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "L4KQsPdKCMTh",
    "outputId": "b0b4af92-c04e-46fb-fd03-6b57e4646d00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25251 images belonging to 6 classes.\n",
      "Found 6308 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "size = 224\n",
    "batch_size=32\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "train_gen = train_data_gen.flow_from_directory(\"../input/vietai-c6-assignment3-extracted-dataset/train\", batch_size=batch_size,\n",
    "                                              target_size=(size, size), subset=\"training\")\n",
    "valid_gen = train_data_gen.flow_from_directory(\"../input/vietai-c6-assignment3-extracted-dataset/train\", batch_size=batch_size,\n",
    "                                              target_size=(size, size), subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "FECQnh8iZniz"
   },
   "outputs": [],
   "source": [
    "\n",
    "# try:\n",
    "#   tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
    "#   print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
    "# except ValueError:\n",
    "#   raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
    "\n",
    "# tf.config.experimental_connect_to_cluster(tpu)\n",
    "# tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "# tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "p_JBF6pyVkUR"
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tfk.Sequential()\n",
    "    model.add(Conv2D(144, (3, 3), strides=(1, 1), padding=\"valid\", input_shape=(224, 224, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPool2D())\n",
    "    model.add(Conv2D(94, (3, 3), strides=(1, 1), padding=\"valid\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPool2D())\n",
    "    model.add(Conv2D(144, (3, 3), strides=(1, 1), padding=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPool2D())\n",
    "    model.add(Conv2D(94, (3, 3), strides=(1, 1), padding=\"valid\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPool2D())\n",
    "    model.add(Conv2D(42, (3, 3), strides=(1, 1), padding=\"valid\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPool2D())\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.21))\n",
    "    model.add(Dense(256, activation=\"tanh\", kernel_regularizer=tf.keras.regularizers.l2()))\n",
    "    model.add(Dropout(0.21))\n",
    "    model.add(Dense(256, activation=\"tanh\", kernel_regularizer=tf.keras.regularizers.l2()))\n",
    "    model.add(Dropout(0.21))\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "CABYt5oPVoF1"
   },
   "outputs": [],
   "source": [
    "def create_pretrained_model():\n",
    "    model = tfk.Sequential()\n",
    "    pretrained_net = tfk.applications.DenseNet201(\n",
    "        include_top=False,\n",
    "        input_shape=(224, 224, 3),\n",
    "        pooling=\"avg\"\n",
    "    )\n",
    "    # efficientnet.trainable = False\n",
    "    model.add(pretrained_net)\n",
    "#     model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dropout(0.42))\n",
    "    model.add(Dense(256, activation=\"tanh\", kernel_regularizer=tf.keras.regularizers.l2()))\n",
    "    model.add(Dropout(0.21))\n",
    "    model.add(Dense(128, activation=\"tanh\", kernel_regularizer=tf.keras.regularizers.l2()))\n",
    "    model.add(Dropout(0.21))\n",
    "    model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WwWNxAxpCMTl"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get(\"val_accuracy\") is not None:\n",
    "            if(logs.get('val_accuracy') > 0.99):\n",
    "                print(\"\\nReached 99% val_accuracy so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "mcb = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "m6JONgdqgPpO",
    "outputId": "cef55481-0c2d-4a08-9e90-98b47d39cedb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "74842112/74836368 [==============================] - 4s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Model)          (None, 1920)              18321984  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               491776    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 18,847,430\n",
      "Trainable params: 18,618,374\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n",
      "Epoch 1/150\n",
      "790/790 [==============================] - 270s 342ms/step - loss: 6.4192 - accuracy: 0.7345 - val_loss: 5.3807 - val_accuracy: 0.9228 - lr: 1.0000e-05\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 8.8e-05.\n",
      "Epoch 2/150\n",
      "790/790 [==============================] - 259s 328ms/step - loss: 3.5183 - accuracy: 0.9174 - val_loss: 2.4513 - val_accuracy: 0.9420 - lr: 8.8000e-05\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.000166.\n",
      "Epoch 3/150\n",
      "790/790 [==============================] - 258s 327ms/step - loss: 1.6244 - accuracy: 0.9345 - val_loss: 1.0437 - val_accuracy: 0.9241 - lr: 1.6600e-04\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.000244.\n",
      "Epoch 4/150\n",
      "790/790 [==============================] - 258s 327ms/step - loss: 0.6240 - accuracy: 0.9333 - val_loss: 0.3836 - val_accuracy: 0.9339 - lr: 2.4400e-04\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.000322.\n",
      "Epoch 5/150\n",
      "790/790 [==============================] - 259s 328ms/step - loss: 0.3131 - accuracy: 0.9314 - val_loss: 0.3882 - val_accuracy: 0.8922 - lr: 3.2200e-04\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0004.\n",
      "Epoch 6/150\n",
      "790/790 [==============================] - 259s 328ms/step - loss: 0.3010 - accuracy: 0.9204 - val_loss: 0.4861 - val_accuracy: 0.8630 - lr: 4.0000e-04\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.000322.\n",
      "Epoch 7/150\n",
      "790/790 [==============================] - 258s 327ms/step - loss: 0.1963 - accuracy: 0.9528 - val_loss: 0.4558 - val_accuracy: 0.8673 - lr: 3.2200e-04\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0002596000000000001.\n",
      "Epoch 8/150\n",
      "790/790 [==============================] - 258s 327ms/step - loss: 0.1545 - accuracy: 0.9639 - val_loss: 0.2365 - val_accuracy: 0.9339 - lr: 2.5960e-04\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.00020968000000000004.\n",
      "Epoch 9/150\n",
      "790/790 [==============================] - 259s 328ms/step - loss: 0.1111 - accuracy: 0.9779 - val_loss: 0.3288 - val_accuracy: 0.9138 - lr: 2.0968e-04\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.00016974400000000002.\n",
      "Epoch 10/150\n",
      "790/790 [==============================] - 260s 329ms/step - loss: 0.0754 - accuracy: 0.9878 - val_loss: 0.1970 - val_accuracy: 0.9504 - lr: 1.6974e-04\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.00013779520000000003.\n",
      "Epoch 11/150\n",
      "790/790 [==============================] - 260s 329ms/step - loss: 0.0612 - accuracy: 0.9918 - val_loss: 0.1824 - val_accuracy: 0.9553 - lr: 1.3780e-04\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.00011223616000000004.\n",
      "Epoch 12/150\n",
      "790/790 [==============================] - 260s 329ms/step - loss: 0.0464 - accuracy: 0.9956 - val_loss: 0.1750 - val_accuracy: 0.9572 - lr: 1.1224e-04\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 9.178892800000003e-05.\n",
      "Epoch 13/150\n",
      "790/790 [==============================] - 258s 327ms/step - loss: 0.0416 - accuracy: 0.9956 - val_loss: 0.3303 - val_accuracy: 0.9231 - lr: 9.1789e-05\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 7.543114240000003e-05.\n",
      "Epoch 14/150\n",
      "790/790 [==============================] - 259s 328ms/step - loss: 0.0362 - accuracy: 0.9975 - val_loss: 0.1422 - val_accuracy: 0.9651 - lr: 7.5431e-05\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 6.234491392000002e-05.\n",
      "Epoch 15/150\n",
      "790/790 [==============================] - 258s 327ms/step - loss: 0.0304 - accuracy: 0.9985 - val_loss: 0.1496 - val_accuracy: 0.9615 - lr: 6.2345e-05\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 5.1875931136000024e-05.\n",
      "Epoch 16/150\n",
      "790/790 [==============================] - 260s 329ms/step - loss: 0.0264 - accuracy: 0.9992 - val_loss: 0.1739 - val_accuracy: 0.9588 - lr: 5.1876e-05\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 4.3500744908800015e-05.\n",
      "Epoch 17/150\n",
      "790/790 [==============================] - 258s 326ms/step - loss: 0.0257 - accuracy: 0.9991 - val_loss: 0.1539 - val_accuracy: 0.9643 - lr: 4.3501e-05\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 3.6800595927040014e-05.\n",
      "Epoch 18/150\n",
      "790/790 [==============================] - 258s 327ms/step - loss: 0.0219 - accuracy: 0.9996 - val_loss: 0.1571 - val_accuracy: 0.9610 - lr: 3.6801e-05\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 3.1440476741632015e-05.\n",
      "Epoch 19/150\n",
      "790/790 [==============================] - 258s 327ms/step - loss: 0.0202 - accuracy: 0.9998 - val_loss: 0.1621 - val_accuracy: 0.9621 - lr: 3.1440e-05\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 2.7152381393305616e-05.\n",
      "Epoch 20/150\n",
      "790/790 [==============================] - 258s 327ms/step - loss: 0.0198 - accuracy: 0.9998 - val_loss: 0.1445 - val_accuracy: 0.9646 - lr: 2.7152e-05\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 2.3721905114644494e-05.\n",
      "Epoch 21/150\n",
      "790/790 [==============================] - 258s 327ms/step - loss: 0.0187 - accuracy: 0.9998 - val_loss: 0.1492 - val_accuracy: 0.9639 - lr: 2.3722e-05\n",
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 2.0977524091715595e-05.\n",
      "Epoch 22/150\n",
      "790/790 [==============================] - 258s 327ms/step - loss: 0.0170 - accuracy: 0.9998 - val_loss: 0.1524 - val_accuracy: 0.9645 - lr: 1.5620e-05\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 1.4496393867966709e-05.\n",
      "Epoch 26/150\n",
      "790/790 [==============================] - 257s 326ms/step - loss: 0.0165 - accuracy: 0.9998 - val_loss: 0.1574 - val_accuracy: 0.9632 - lr: 1.3597e-05\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 1.2877692075498695e-05.\n",
      "Epoch 28/150\n",
      "790/790 [==============================] - 258s 326ms/step - loss: 0.0157 - accuracy: 0.9999 - val_loss: 0.1524 - val_accuracy: 0.9637 - lr: 1.2302e-05\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 1.1841722928319164e-05.\n",
      "Epoch 30/150\n",
      "790/790 [==============================] - 258s 327ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.1555 - val_accuracy: 0.9631 - lr: 1.1473e-05\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 1.1178702674124267e-05.\n",
      "Epoch 32/150\n",
      "790/790 [==============================] - 258s 327ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 0.9650 - lr: 1.0943e-05\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 1.075436971143953e-05.\n",
      "Epoch 34/150\n",
      "230/790 [=======>......................] - ETA: 2:49 - loss: 0.0141 - accuracy: 1.0000"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "use_efficientnet = True\n",
    "if not use_efficientnet:\n",
    "    model = create_model()\n",
    "else:\n",
    "    model = create_pretrained_model()\n",
    "\n",
    "start_lr = 0.00001\n",
    "min_lr = 0.00001\n",
    "max_lr = 0.00005*8\n",
    "rampup_epochs = 5\n",
    "sustain_epochs = 0\n",
    "exp_decay = .8\n",
    "\n",
    "def lrfn(epoch):\n",
    "    if epoch < rampup_epochs:\n",
    "        return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n",
    "    elif epoch < rampup_epochs + sustain_epochs:\n",
    "        return max_lr\n",
    "    else:\n",
    "        return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n",
    "\n",
    "mcp = tf.keras.callbacks.ModelCheckpoint(\"my_model.h5\", monitor=\"val_accuracy\",\n",
    "                        save_best_only=True, save_weights_only=True)\n",
    "val_acc_earlyStop = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", \n",
    "                                                         patience = epochs//15, restore_best_weights = True)\n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=True)\n",
    "\n",
    "model.fit(train_gen, validation_data=valid_gen, epochs=epochs, callbacks=[mcp, mcb, val_acc_earlyStop, lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "CdaH9lUUCMTy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "densenet201 (Model)          (None, 1920)              18321984  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               491776    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 18,847,430\n",
      "Trainable params: 18,618,374\n",
      "Non-trainable params: 229,056\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = create_pretrained_model()\n",
    "model.build(input_shape=(1,224,224,3))\n",
    "model.load_weights(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Hrgc1T-LCMT1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3837 images belonging to 1 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10010.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10011.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10028.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10034.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10056.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10081.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10084.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10091.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>101.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1010.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10107.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10115.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10132.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10133.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10137.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10138.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10167.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1017.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10204.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10208.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image  label\n",
       "0   10010.jpg      2\n",
       "1   10011.jpg      1\n",
       "2   10028.jpg      2\n",
       "3   10034.jpg      3\n",
       "4   10056.jpg      5\n",
       "5   10081.jpg      2\n",
       "6   10084.jpg      1\n",
       "7   10091.jpg      3\n",
       "8     101.jpg      0\n",
       "9    1010.jpg      5\n",
       "10  10107.jpg      1\n",
       "11  10115.jpg      1\n",
       "12  10132.jpg      0\n",
       "13  10133.jpg      3\n",
       "14  10137.jpg      4\n",
       "15  10138.jpg      0\n",
       "16  10167.jpg      5\n",
       "17   1017.jpg      0\n",
       "18  10204.jpg      3\n",
       "19  10208.jpg      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_gen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_generator = test_data_gen.flow_from_directory(\"../input/vietai-c6-assignment3-extracted-dataset/test\",class_mode=None, target_size=(size, size), shuffle=False)\n",
    "test_generator.reset()\n",
    "pred = model.predict(test_generator)\n",
    "\n",
    "# pred là một ma trận xác suất của ảnh trên các lớp.\n",
    "# Ta lấy lớp có xác suất cao nhất trên từng ảnh bằng hàm argmax\n",
    "pred_labels = np.argmax(pred, axis=1)\n",
    "sub_df['label'] = pred_labels\n",
    "sub_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "riWkqzkACMT7"
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
