{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN3_Sentiment_Analysis",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts2Lr3ze9yZ9",
        "colab_type": "text"
      },
      "source": [
        "## Part 3: Sentiment Analysis\n",
        "IMDB review dataset will be downloaded. We will classify if a review is positive or negative or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaXSzALR2gS2",
        "colab_type": "text"
      },
      "source": [
        "## Download GloVe word vectors: LOAD THIS PART \n",
        "Other options are:  \n",
        "glove.6B.zip: from Wikipedia + Gigaword, 6B tokens, 400K vocab, uncased, 50d, 100d, 200d and 300d vectors, 822MB download  \n",
        "glove.42B.300d.zip: from Common Crawl, 42B tokens, 1.9M vocab, uncased, 300d vectors, 1.75 GB download  \n",
        "glove.840B.300d.zip: from Common Crawl, 840B tokens, 2.2M vocab, cased, 300d vectors, 2.03 GB download  \n",
        "glove.twitter.27B.zip: from Twitter, 2B tweets, 27B tokens, 1.2M vocab, uncased, 25d, 50d, 100d, & 200d vectors, 1.42 GB download  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOY1Oeppw1VW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "%%bash\n",
        "wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "unzip -q glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFZsRHMatWNU",
        "colab_type": "text"
      },
      "source": [
        "Might took a while to download."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZSzuFvX4N5B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AAIxyBBaDmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_glove_file = os.path.join(\n",
        "    os.path.expanduser(\"~\"), \"/content/glove.6B.100d.txt\"\n",
        ")\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(\"Found %s word vectors.\" % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3JHQHmXiGVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(list(embeddings_index.items())[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLaH67GN-ZtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agMYcHZE-dCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size = info.splits[\"train\"].num_examples\n",
        "test_size = info.splits[\"test\"].num_examples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgSynAI0-iRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size, test_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q0XlOvb4p2M",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhB07qFk-j5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_samples = []\n",
        "train_labels = []\n",
        "for x_batch, y_batch in datasets[\"train\"].batch(64):\n",
        "    for review, label in zip(x_batch.numpy(), y_batch.numpy()):\n",
        "        train_samples.append(review.decode(\"utf-8\"))\n",
        "        train_labels.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO0As_Ej_7nP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_samples = []\n",
        "test_labels = []\n",
        "for x_batch, y_batch in datasets[\"test\"].batch(64):\n",
        "    for review, label in zip(x_batch.numpy(), y_batch.numpy()):\n",
        "        test_samples.append(review.decode(\"utf-8\"))\n",
        "        test_labels.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rlba2z0VAe3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(train_samples), len(test_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BD7s-9XDEc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(data):\n",
        "    '''\n",
        "    Credit goes to https://www.kaggle.com/gpreda/jigsaw-fast-compact-solution\n",
        "    '''\n",
        "    punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~`\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n",
        "    def clean_special_chars(text, punct):\n",
        "        for p in punct:\n",
        "            text = text.replace(p, ' ')\n",
        "        return text\n",
        "\n",
        "    return clean_special_chars(data, punct)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "383xaHS9C6PM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_train_samples = [preprocess(x) for x in train_samples]\n",
        "processed_test_samples = [preprocess(x) for x in test_samples]\n",
        "processed_train_samples[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjLt1DMUD2Ck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split data intro valid and train\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_samples, val_samples, train_labels, val_labels = train_test_split(processed_train_samples, train_labels,\n",
        "                                                                        test_size=0.2, random_state=42, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgxZZ0B8DqeP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Count word frequencies\n",
        "num_words = [len(x.split()) for x in processed_train_samples]\n",
        "print('The total number of samples is', len(processed_train_samples))\n",
        "print('The total number of words in the files is', sum(num_words))\n",
        "print('The average number of words in the files is', sum(num_words)/len(num_words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMWGZRRTESx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.hist(num_words, bins=\"auto\")\n",
        "plt.xlabel('Num of words in sentences')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFCv3br-_giw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "TODO 1: Create Vocabulary index with TextVectorization\n",
        "\"\"\"\n",
        "\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "vocab_size = 20000\n",
        "max_sentence_length = 700\n",
        "batch_size = 64\n",
        "vectorizer = TextVectorization(max_tokens=vocab_size, output_sequence_length=max_sentence_length)\n",
        "text_dataset = tf.data.Dataset.from_tensor_slices(processed_train_samples).batch(batch_size)\n",
        "vectorizer.adapt(text_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONJqEbXv_xRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectorizer.get_vocabulary()[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwalIqPIASo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "voc = vectorizer.get_vocabulary()\n",
        "print(len(voc))\n",
        "word_index = dict(zip(voc, range(2, len(voc))))\n",
        "print(list(word_index.items())[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZ-VQyKFGb_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_output = vectorizer(np.array([[\"I am about to generate fake Shakespearian text!\"]]))\n",
        "sample_output.numpy()[0, :10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hobOzJ9hKE8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert into Numpy array\n",
        "train_samples = np.asarray(train_samples)\n",
        "train_labels = np.asarray(train_labels)\n",
        "val_samples = np.asarray(val_samples)\n",
        "val_labels = np.asarray(val_labels)\n",
        "test_samples = np.asarray(test_samples)\n",
        "test_labels = np.asarray(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-6Aaa1AAVgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_tokens = len(voc) + 2\n",
        "embedding_dim = 100\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix\n",
        "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdUzaymdAYOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras import Input\n",
        "\n",
        "embedding_layer = Embedding(num_tokens, embedding_dim, \n",
        "                            embeddings_initializer = tf.keras.initializers.Constant(embedding_matrix),\n",
        "                            trainable=False)\n",
        "input_layer = Input(shape=(1,), dtype=tf.string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgDiRgr4Bg19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential, Input\n",
        "from tensorflow.keras.layers import GRU, Bidirectional, Dense, Embedding\n",
        "from tensorflow.keras.initializers import Constant\n",
        "\n",
        "# Sample model 1: normal RNN\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        input_layer,\n",
        "        vectorizer,\n",
        "         Embedding(num_tokens, embedding_dim, \n",
        "                            embeddings_initializer = Constant(embedding_matrix), trainable=False),\n",
        "        Bidirectional(GRU(256, return_sequences=True)),\n",
        "        Bidirectional(GRU(128)),\n",
        "        Dense(128, activation=\"tanh\"),\n",
        "        Dense(64, activation=\"tanh\"),\n",
        "        Dense(1, activation=\"sigmoid\")                  \n",
        "    ])\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgdof9yjDlio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(train_samples, train_labels, epochs=30, validation_data=(val_samples, val_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-LTqHhG5POO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot accuracy vs epoch\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}